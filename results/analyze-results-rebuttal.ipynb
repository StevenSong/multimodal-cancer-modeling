{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Analyze Survival Model Results\n",
    "\n",
    "The primary endpoints of our analysis are concordance index (C-index) and risk stratification. This notebook analyzes several facets of our results. Each subheading in this notebook should be self contained (that is, it does not depend on or influence other sections of the notebook). The only exception is the **Setup** section which must be run prior to any given section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.nonparametric import kaplan_meier_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"split_cases.csv\")\n",
    "assert df[\"case_id\"].is_unique\n",
    "df = df.set_index(\"case_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_outcome_array(df):\n",
    "    y = np.array(\n",
    "        list(zip(df[\"dead\"], df[\"days_to_death_or_censor\"])),\n",
    "        dtype=[(\"Status\", \"?\"), (\"Survival_in_days\", \"<f8\")],\n",
    "    )\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_survival_curve(y, max_time=3650, interpolate=True):\n",
    "    time, survival_prob = kaplan_meier_estimator(y[\"Status\"], y[\"Survival_in_days\"])\n",
    "    time[0] = 0\n",
    "    if not interpolate:\n",
    "        return time, survival_prob\n",
    "    interp_time = np.linspace(0, max_time, max_time+1)\n",
    "    interp_prob = np.interp(interp_time, time, survival_prob)\n",
    "    return interp_time, interp_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_split_lo_hi_risk_curves(risk_scores, split_df, interpolate=True):\n",
    "    pivot = np.median(risk_scores)\n",
    "    lo_risk_idxs = np.argwhere(risk_scores < pivot).squeeze(-1)\n",
    "    hi_risk_idxs = np.argwhere(risk_scores >= pivot).squeeze(-1)\n",
    "    lo_risk_cases = split_df.loc[lo_risk_idxs, \"case_id\"]\n",
    "    hi_risk_cases = split_df.loc[hi_risk_idxs, \"case_id\"]\n",
    "    split_df = split_df.set_index(\"case_id\")\n",
    "    lo_risk_df = split_df.loc[lo_risk_cases]\n",
    "    hi_risk_df = split_df.loc[hi_risk_cases]\n",
    "    lo_risk_y = make_outcome_array(lo_risk_df)\n",
    "    hi_risk_y = make_outcome_array(hi_risk_df)\n",
    "    lo_risk_time, lo_risk_prob = fit_survival_curve(lo_risk_y, interpolate=interpolate)\n",
    "    hi_risk_time, hi_risk_prob = fit_survival_curve(hi_risk_y, interpolate=interpolate)\n",
    "    return {\n",
    "        \"lo_risk\": {\n",
    "            \"time\": lo_risk_time,\n",
    "            \"prob\": lo_risk_prob,\n",
    "        },\n",
    "        \"hi_risk\": {\n",
    "            \"time\": hi_risk_time,\n",
    "            \"prob\": hi_risk_prob,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_lo_hi_risk_curves(preds, df):\n",
    "    lo_risk_times = []\n",
    "    lo_risk_probs = []\n",
    "    hi_risk_times = []\n",
    "    hi_risk_probs = []\n",
    "    c_idxs = []\n",
    "    for i in range(5):\n",
    "        split_df = df[df[\"split\"] == i].sort_values(\"split_order\").reset_index()\n",
    "        c_idx = preds[i][\"c_index\"]\n",
    "        c_idxs.append(c_idx)\n",
    "\n",
    "        risk_scores = preds[i][\"y_test_pred\"]\n",
    "        curves = per_split_lo_hi_risk_curves(risk_scores, split_df)\n",
    "        lo_risk_times.append(curves[\"lo_risk\"][\"time\"])\n",
    "        lo_risk_probs.append(curves[\"lo_risk\"][\"prob\"])\n",
    "        hi_risk_times.append(curves[\"hi_risk\"][\"time\"])\n",
    "        hi_risk_probs.append(curves[\"hi_risk\"][\"prob\"])\n",
    "\n",
    "    lo_risk_time_mean = np.mean(lo_risk_times, axis=0)\n",
    "    lo_risk_prob_mean = np.mean(lo_risk_probs, axis=0)\n",
    "    lo_risk_prob_std = np.std(lo_risk_probs, axis=0)\n",
    "\n",
    "    hi_risk_time_mean = np.mean(hi_risk_times, axis=0)\n",
    "    hi_risk_prob_mean = np.mean(hi_risk_probs, axis=0)\n",
    "    hi_risk_prob_std = np.std(hi_risk_probs, axis=0)\n",
    "\n",
    "    c_idx_mean = np.mean(c_idxs)\n",
    "    c_idx_std = np.std(c_idxs)\n",
    "\n",
    "    return {\n",
    "        \"lo_risk\": {\n",
    "            \"time\": lo_risk_time_mean,\n",
    "            \"prob\": {\n",
    "                \"mean\": lo_risk_prob_mean,\n",
    "                \"std\": lo_risk_prob_std,\n",
    "            }\n",
    "        },\n",
    "        \"hi_risk\": {\n",
    "            \"time\": hi_risk_time_mean,\n",
    "            \"prob\": {\n",
    "                \"mean\": hi_risk_prob_mean,\n",
    "                \"std\": hi_risk_prob_std,\n",
    "            }\n",
    "        },\n",
    "        \"c_index\": {\n",
    "            \"mean\": c_idx_mean,\n",
    "            \"std\": c_idx_std,\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(\n",
    "    *,  # enforce kwargs\n",
    "    ax: plt.Axes,\n",
    "    results: dict,\n",
    "    name: str,\n",
    "    color: str,\n",
    "    plot_std: bool = True,\n",
    "    linestyle: str | None = None,\n",
    "    include_cidx: bool = True,\n",
    "):\n",
    "    c_idx_mean = results[\"c_index\"][\"mean\"]\n",
    "    c_idx_std = results[\"c_index\"][\"std\"]\n",
    "    label = name\n",
    "    if include_cidx:\n",
    "        label += f\", C-index = {c_idx_mean:0.2f}\"\n",
    "        if not plot_std and c_idx_std is not None:\n",
    "            label += f\"±{c_idx_std:0.2f}\"\n",
    "    ax.step(\n",
    "        results[\"lo_risk\"][\"time\"],\n",
    "        results[\"lo_risk\"][\"prob\"][\"mean\"],\n",
    "        where=\"post\",\n",
    "        color=color,\n",
    "        label=label,\n",
    "        linestyle=linestyle,\n",
    "    )\n",
    "    if plot_std:\n",
    "        ax.fill_between(\n",
    "            results[\"lo_risk\"][\"time\"],\n",
    "            results[\"lo_risk\"][\"prob\"][\"mean\"] - results[\"lo_risk\"][\"prob\"][\"std\"],\n",
    "            results[\"lo_risk\"][\"prob\"][\"mean\"] + results[\"lo_risk\"][\"prob\"][\"std\"],\n",
    "            alpha=0.25,\n",
    "            step=\"post\",\n",
    "            color=color,\n",
    "            label=f\"±1 std. dev. = {c_idx_std:0.2f}\",\n",
    "        )\n",
    "\n",
    "    ax.step(\n",
    "        results[\"hi_risk\"][\"time\"],\n",
    "        results[\"hi_risk\"][\"prob\"][\"mean\"],\n",
    "        where=\"post\",\n",
    "        color=color,\n",
    "        linestyle=linestyle,\n",
    "    )\n",
    "    if plot_std:\n",
    "        ax.fill_between(\n",
    "            results[\"hi_risk\"][\"time\"],\n",
    "            results[\"hi_risk\"][\"prob\"][\"mean\"] - results[\"hi_risk\"][\"prob\"][\"std\"],\n",
    "            results[\"hi_risk\"][\"prob\"][\"mean\"] + results[\"hi_risk\"][\"prob\"][\"std\"],\n",
    "            alpha=0.25,\n",
    "            step=\"post\",\n",
    "            color=color,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(\n",
    "    *,  # enforce kwargs\n",
    "    modes: list[\n",
    "        tuple[\n",
    "            str,  # modality name\n",
    "            str,  # modality color\n",
    "            dict,  # modality results\n",
    "        ],\n",
    "    ],\n",
    "    save_path: str | list[str] | None = None,\n",
    "    plot_std: bool = True,\n",
    "    include_cidx: bool = True,\n",
    "    linestyles: list[str] | None = None,\n",
    "    fig: plt.Figure | None = None,\n",
    "    ax: plt.Axes | None = None,\n",
    "):\n",
    "    if ax is None:\n",
    "        assert fig is None\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "    for i, (name, color, results) in enumerate(modes):\n",
    "        linestyle = None\n",
    "        if linestyles is not None:\n",
    "            linestyle = linestyles[i]\n",
    "        plot_results(ax=ax, results=results, name=name, color=color, plot_std=plot_std, linestyle=linestyle, include_cidx=include_cidx)\n",
    "\n",
    "    ax.set_ylim(0, 1.05)\n",
    "    ax.set_xlim(0, 3650)\n",
    "    ax.legend(loc=\"lower left\")\n",
    "    ax.set_ylabel(\"Survival Probability\")\n",
    "    ax.set_xlabel(\"Days\")\n",
    "    if fig is not None:\n",
    "        fig.tight_layout()\n",
    "        if save_path is not None:\n",
    "            if isinstance(save_path, str):\n",
    "                save_path = [save_path]\n",
    "            for sp in save_path: # accomodates for different file endings\n",
    "                fig.savefig(sp, dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Project Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_components = 256\n",
    "modes = {\n",
    "    \"demo\": (\"demo\", \"predictions_summarized.npy\"),\n",
    "    # \"canc\": (\"canc\", \"predictions_summarized.npy\"),\n",
    "    \"expr\": (\"expr\", \"predictions_summarized.npy\"),\n",
    "    \"hist\": (\"hist\", \"predictions_summarized.npy\"),\n",
    "    \"text\": (\"text\", \"predictions_summarized.npy\"),\n",
    "    \"orig\": (\"text\", \"predictions.npy\"),\n",
    "    \"canc-demo-expr-hist-text\": (\"canc-demo-expr-hist-text\", \"predictions_summarized.npy\"),\n",
    "}\n",
    "data = dict()\n",
    "for mode, (key, pred_file) in modes.items():\n",
    "    preds = np.load(pred_file, allow_pickle=True).item()[pca_components]\n",
    "    datum = [preds[i][key] for i in range(5)]\n",
    "    data[mode] = datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv(\"../data/clinical.csv\")\n",
    "assert not meta[\"case_id\"].duplicated().any()\n",
    "meta = meta.set_index(\"case_id\")\n",
    "meta = pd.merge(df, meta, left_index=True, right_index=True)\n",
    "df[\"project\"] = meta.loc[df.index, \"project\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_project = defaultdict(lambda: defaultdict(list))\n",
    "for proj_rank, project in enumerate(df[\"project\"].value_counts().index):\n",
    "    print(proj_rank, project)\n",
    "# for project in df[\"project\"].value_counts().head(8).index:\n",
    "    proj_df = df[df[\"project\"] == project]\n",
    "    for i in range(5):\n",
    "        proj_split_df = proj_df[proj_df[\"split\"] == i].sort_values(\"split_order\")\n",
    "        proj_split_idxs = proj_split_df[\"split_order\"].to_numpy()\n",
    "        proj_split_y_test = make_outcome_array(proj_split_df)\n",
    "\n",
    "        died_mask = proj_split_y_test[\"Status\"]\n",
    "        died_survival = proj_split_y_test[died_mask][\"Survival_in_days\"]\n",
    "        no_c_index = (\n",
    "            died_mask.sum() == 0 # all censored\n",
    "            or (\n",
    "                # no comparable pairs\n",
    "                died_mask.sum() < 2\n",
    "                and died_survival[0] == proj_split_y_test[\"Survival_in_days\"].max()\n",
    "            )\n",
    "        )\n",
    "        skip = False\n",
    "        if no_c_index:\n",
    "            # given 5-fold cross validation with splits stratified by death\n",
    "            # we can pretty much guarantee that projects with < 10 deaths\n",
    "            # will have \"bad\" survival data\n",
    "            # raise ValueError(f\"Bad Survival Data {project} Split {i}\")\n",
    "            if died_mask.sum() == 0:\n",
    "                reason = \"all censored\"\n",
    "            else:\n",
    "                reason = \"no comparable pairs\"\n",
    "            print(f\"Bad Survival Data {project} Split {i} because {reason}\")\n",
    "            skip = True\n",
    "\n",
    "        for mode, datum in data.items():\n",
    "            proj_split_y_test_pred = datum[i][\"y_test_pred\"][proj_split_idxs]\n",
    "            if not skip:\n",
    "                proj_split_c_index = concordance_index_censored(\n",
    "                    event_indicator=proj_split_y_test[\"Status\"],\n",
    "                    event_time=proj_split_y_test[\"Survival_in_days\"],\n",
    "                    estimate=proj_split_y_test_pred,\n",
    "                )[0]\n",
    "            else:\n",
    "                proj_split_c_index = -1\n",
    "            data_by_project[project][mode].append(\n",
    "                {\n",
    "                    \"c_index\": proj_split_c_index,\n",
    "                    \"y_test_pred\": proj_split_y_test_pred,\n",
    "                }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))\n",
    "results_by_project = dict()\n",
    "for i, project in enumerate(df[\"project\"].value_counts().index):\n",
    "# for i, project in enumerate(df[\"project\"].value_counts().head(8).index):\n",
    "    # ax = axs[i // 4, i % 4]\n",
    "    data = data_by_project[project]\n",
    "    if any([x[\"c_index\"] == -1 for x in data[\"demo\"]]):\n",
    "        print(\"Skipping\", i, project)\n",
    "        continue\n",
    "    proj_df = df[df[\"project\"] == project]\n",
    "\n",
    "    demo_results = cross_val_lo_hi_risk_curves(data[\"demo\"], proj_df)\n",
    "    # canc_results = cross_val_lo_hi_risk_curves(data[\"canc\"], proj_df)\n",
    "    expr_results = cross_val_lo_hi_risk_curves(data[\"expr\"], proj_df)\n",
    "    hist_results = cross_val_lo_hi_risk_curves(data[\"hist\"], proj_df)\n",
    "    text_results = cross_val_lo_hi_risk_curves(data[\"text\"], proj_df)\n",
    "    orig_results = cross_val_lo_hi_risk_curves(data[\"orig\"], proj_df)\n",
    "    mult_results = cross_val_lo_hi_risk_curves(data[\"canc-demo-expr-hist-text\"], proj_df)\n",
    "\n",
    "    # plot_comparison(\n",
    "    #     modes=[\n",
    "    #         (\"Demographics\", \"tab:blue\", demo_results),\n",
    "    #         # (\"Cancer Type\", \"tab:blue\", canc_results),\n",
    "    #         (\"RNA-seq\", \"tab:orange\", expr_results),\n",
    "    #         (\"Histology\", \"tab:green\", hist_results),\n",
    "    #         (\"Text\", \"tab:purple\", text_results),\n",
    "    #         (\"Multimodal\", \"tab:red\", mult_results),\n",
    "    #     ],\n",
    "    #     plot_std=False,\n",
    "    #     ax=ax,\n",
    "    # )\n",
    "\n",
    "    results_by_project[project.replace(\"TCGA-\", \"\")] = {\n",
    "        \"Mean Split Size\": f'{proj_df.groupby(\"split\").size().mean():0.1f}',\n",
    "        \"Mean Split Mortality\": f'{proj_df.groupby(\"split\")[\"dead\"].sum().mean():0.1f}',\n",
    "        \"Demographics\": demo_results[\"c_index\"][\"mean\"],\n",
    "        # \"Cancer type\": canc_results[\"c_index\"][\"mean\"],\n",
    "        \"RNA-seq\": expr_results[\"c_index\"][\"mean\"],\n",
    "        \"Histology\": hist_results[\"c_index\"][\"mean\"],\n",
    "        \"Text\": text_results[\"c_index\"][\"mean\"],\n",
    "        \"Orig\": orig_results[\"c_index\"][\"mean\"],\n",
    "        \"Multimodal\": mult_results[\"c_index\"][\"mean\"],\n",
    "    }\n",
    "results_by_project = pd.DataFrame(results_by_project)\n",
    "results_by_project.index.name = \"Modality\"\n",
    "results_by_project = results_by_project.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_by_project.loc[[0, 1, 2, 3, 4, 5, 7]].iloc[:, [0] + list(range(1, 8))].to_markdown(index=False, floatfmt=\"0.3f\"))\n",
    "print(results_by_project.loc[[0, 1, 2, 3, 4, 5, 7]].iloc[:, [0] + list(range(8, 15))].to_markdown(index=False, floatfmt=\"0.3f\"))\n",
    "print(results_by_project.loc[[0, 1, 2, 3, 4, 5, 7]].iloc[:, [0] + list(range(15, 22))].to_markdown(index=False, floatfmt=\"0.3f\"))\n",
    "print(results_by_project.loc[[0, 1, 2, 3, 4, 5, 7]].iloc[:, [0] + list(range(22, 28))].to_markdown(index=False, floatfmt=\"0.3f\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Multimodal Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = pd.read_csv(\"results_summarized.csv\")\n",
    "trials = trials.rename(columns={\"Unnamed: 0\": \"combo\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebuttal to reviewer oaBB\n",
    "temp = trials.loc[trials[\"combo\"].str.contains(\"canc\"), [\"combo\", \"256\"]]\n",
    "temp.loc[[0, 5], \"256\"] = trials.loc[[0, 5], \"4\"]\n",
    "temp = temp.rename(columns={\"256\": \"C-index\"})\n",
    "print(temp.to_markdown(index=False, floatfmt=\"0.3f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Qualitative Analysis of Hallucination Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "# copy paste from SO: https://stackoverflow.com/a/64404008\n",
    "# red = lambda text: f\"\\033[38;2;255;0;0m{text}\\033[38;2;255;255;255m\"\n",
    "# green = lambda text: f\"\\033[38;2;0;255;0m{text}\\033[38;2;255;255;255m\"\n",
    "# blue = lambda text: f\"\\033[38;2;0;0;255m{text}\\033[38;2;255;255;255m\"\n",
    "# white = lambda text: f\"\\033[38;2;255;255;255m{text}\\033[38;2;255;255;255m\"\n",
    "\n",
    "red = lambda text: f'<span style=\"color: red;\">{text}</span>'\n",
    "green = lambda text: f'<span style=\"color: green;\">{text}</span>'\n",
    "blue = lambda text: f'<span style=\"color: blue;\">{text}</span>'\n",
    "white = lambda text: text\n",
    "\n",
    "def get_edits_string(old, new):\n",
    "    result = \"\"\n",
    "    codes = difflib.SequenceMatcher(a=old, b=new).get_opcodes()\n",
    "    for code in codes:\n",
    "        if code[0] == \"equal\": \n",
    "            result += white(old[code[1]:code[2]])\n",
    "        elif code[0] == \"delete\":\n",
    "            result += red(old[code[1]:code[2]])\n",
    "        elif code[0] == \"insert\":\n",
    "            result += green(new[code[3]:code[4]])\n",
    "        elif code[0] == \"replace\":\n",
    "            result += (red(old[code[1]:code[2]]) + green(new[code[3]:code[4]]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/sampled_corrected.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the output into an HTML file, easier copy/pasting from the browser rendered text than in notebook\n",
    "for i in df[df[\"summ\"] != df[\"corrected\"]].index:\n",
    "    print(f\"<h3>{df.loc[i, 'case_id']}</h3>\")\n",
    "    print(get_edits_string(df.loc[i, \"summ\"], df.loc[i, \"corrected\"]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "survival",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
